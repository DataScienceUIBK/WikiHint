[English](README.md) | [‰∏≠Êñá](README.zh.md) | [Deutsch](README.de.md) | [Fran√ßais](README.fr.md) | [–†—É—Å—Å–∫–∏–π](README.ru.md)

# WikiHint : Un Jeu de Donn√©es Annot√© par des Humains pour le Classement et la G√©n√©ration d'Indices

<a href="https://doi.org/10.48550/arXiv.2412.01626"><img src="https://img.shields.io/static/v1?label=Article&message=arXiv&color=green&logo=arxiv"></a>
<a href="https://colab.research.google.com/github/DataScienceUIBK/WikiHint/blob/main/HintRank/Demo.ipynb"><img src="https://img.shields.io/static/v1?label=Colab&message=Demo&logo=Google%20Colab&color=f9ab00"></a>
[![License](https://img.shields.io/badge/License-CC%20BY%204.0-blue)](https://creativecommons.org/licenses/by/4.0/)
<img src="https://github.com/DataScienceUIBK/WikiHint/blob/main/WikiHint/Pipeline.png">

WikiHint est un **jeu de donn√©es annot√© par des humains** con√ßu pour la **g√©n√©ration et le classement automatiques d'indices** pour les questions factuelles. Ce jeu de donn√©es, bas√© sur Wikipedia, contient **5 000 indices pour 1 000 questions** et soutient la recherche sur **l‚Äô√©valuation, le classement et la g√©n√©ration d‚Äôindices**.

## üóÇ Vue d‚Äôensemble

- **1 000 questions** avec **5 000 indices cr√©√©s manuellement**.
- Indices class√©s par des **annotateurs humains** selon leur utilit√©.
- √âvalu√© √† l'aide de **LLMs (LLaMA, GPT-4)** et d‚Äô**√©tudes sur la performance humaine**.
- Supporte le **classement des indices** et **l‚Äô√©valuation automatique des indices**.

## üî¨ Contributions √† la recherche

‚úÖ **Premier jeu de donn√©es annot√© par des humains** pour la g√©n√©ration et le classement d'indices.  
‚úÖ **HintRank** : Une m√©thode l√©g√®re pour le classement automatique des indices.  
‚úÖ **√âtude humaine** √©valuant l‚Äôefficacit√© des indices pour aider les utilisateurs √† r√©pondre aux questions.  
‚úÖ **Ajustement fin des LLM open-source** (LLaMA-3.1, GPT-4) pour la g√©n√©ration d‚Äôindices.  

## üìà Principaux enseignements

- **Les indices tenant compte de la r√©ponse** am√©liorent leur efficacit√©.  
- **Les mod√®les LLaMA ajust√©s finement** g√©n√®rent de meilleurs indices que les mod√®les bruts.  
- **Les indices plus courts** ont tendance √† √™tre **plus efficaces** que les plus longs.  
- **Les indices g√©n√©r√©s par des humains** surpassent ceux des LLM en termes de clart√© et de classement.

## üöÄ Prise en main

### 1Ô∏è‚É£ Cloner le d√©p√¥t

```sh
git clone https://github.com/DataScienceUIBK/WikiHint.git
cd WikiHint
```

### 2Ô∏è‚É£ Charger le jeu de donn√©es

```python
import json

with open("./WikiHint/training.json", "r") as f:
    training_data = json.load(f)

with open("./WikiHint/test.json", "r") as f:
    test_data = json.load(f)

print(f"Ensemble d‚Äôentra√Ænement : {len(training_data)} questions")
print(f"Ensemble de test : {len(test_data)} questions")
```

## üèÜ HintRank : Une M√©thode L√©g√®re de Classement des Indices

HintRank est une **m√©thode de classement automatique** des indices utilisant des **mod√®les bas√©s sur BERT**. Il fonctionne sur le principe des **comparaisons par paires**, d√©terminant la **pertinence relative des indices**.

<p align="center">
    <img src="https://raw.githubusercontent.com/DataScienceUIBK/WikiHint/main/HintRank/EvaluationMethod.png" width="35%">
</p>

### ‚ú® Fonctionnalit√©s :
‚úî **L√©ger** : Fonctionne localement sans n√©cessiter de ressources informatiques massives.  
‚úî **√âvaluation sans LLM** : Fonctionne sans d√©pendre de **grands mod√®les g√©n√©ratifs**.  
‚úî **Classement align√© sur les humains** : Forte corr√©lation avec le **classement des indices √©tabli par des humains**.  

### üîç Comment √ßa marche ?
1. **Concat√®ne la question & deux indices** ‚Üí Les convertit au format compatible BERT.  
2. **Calcule la qualit√© des indices** ‚Üí D√©termine quel indice est **le plus utile**.  
3. **G√©n√®re un classement des indices** ‚Üí Attribue un rang bas√© sur des comparaisons par paires.  

## üìå Utilisation de `HintRank` pour le Classement des Indices

Le module `HintRank` est con√ßu pour **classer automatiquement les indices** selon leur pertinence √† l‚Äôaide de **mod√®les bas√©s sur BERT**.

### üöÄ Ex√©cuter la D√©mo HintRank sur Google Colab

Vous pouvez facilement essayer **HintRank** dans votre navigateur via **Google Colab**, sans installation locale requise. Lancez simplement le **[notebook Colab](https://colab.research.google.com/github/DataScienceUIBK/WikiHint/blob/main/HintRank/Demo.ipynb)** pour explorer **HintRank** de mani√®re interactive.

### 1Ô∏è‚É£ Installer les d√©pendances

Si vous ex√©cutez HintRank localement, assurez-vous d‚Äôavoir install√© les d√©pendances requises :

```sh
pip install transformers torch numpy scipy
```

### 2Ô∏è‚É£ Importer et initialiser HintRank

Acc√©dez au r√©pertoire `HintRank` et importez le module `hint_rank` :

```python
from HintRank.hint_rank import HintRank

# Initialiser le mod√®le HintRank
ranker = HintRank()
```

### 3Ô∏è‚É£ Classer les indices pour une question donn√©e

```python
question = "Quelle est la capitale de l'Autriche ?"
answer = "Vienne"
hints = [
    "Mozart et Beethoven y ont v√©cu.",
    "C'est une grande ville en Europe.",
    "La plus grande ville d'Autriche."
]

# Exemple de comparaison par paires
better_hint_answer_aware = ranker.pairwise_compare(question, hints[1], hints[2], answer)
better_hint_answer_agnostic = ranker.pairwise_compare(question, hints[0], hints[1])

print(f"R√©ponse-Consciente : L'indice {2 if better_hint_answer_aware == 1 else 3} est meilleur que l'indice {3 if better_hint_answer_aware == 0 else 2}.")
print(f"R√©ponse-Agnostique : L'indice {1 if better_hint_answer_agnostic == 1 else 2} est meilleur que l'indice {2 if better_hint_answer_agnostic == 0 else 1}.")
```

### 4Ô∏è‚É£ Classement des indices en liste

Vous pouvez √©galement classer plusieurs indices en une seule fois :

```python
print("\nIndices class√©s (R√©ponse-Consciente) :")
ranked_hints_answer_aware = ranker.listwise_compare(question, hints, answer)
for i, (hint, _) in enumerate(ranked_hints_answer_aware):
    print(f"Rang {i + 1} : {hint}")

print("\nIndices class√©s (R√©ponse-Agnostique) :")
ranked_hints_answer_agnostic = ranker.listwise_compare(question, hints)
for i, (hint, _) in enumerate(ranked_hints_answer_agnostic):
    print(f"Rang {i + 1} : {hint}")
```

---

### üìå R√©sultat Attendu

```
Comparaison par Paires des Indices
	R√©ponse-Consciente : L'indice 3 est meilleur que l'indice 2.
	R√©ponse-Agnostique : L'indice 2 est meilleur que l'indice 1.

Classement des Indices en Liste
	Indices Class√©s (R√©ponse-Consciente) :
		Rang 1 : La plus grande ville d'Autriche.
		Rang 2 : Mozart et Beethoven y ont v√©cu.
		Rang 3 : C'est une grande ville en Europe.

	Indices Class√©s (R√©ponse-Agnostique) :
		Rang 1 : C'est une grande ville en Europe.
		Rang 2 : La plus grande ville d'Autriche.
		Rang 3 : Mozart et Beethoven y ont v√©cu.
```

---

## üìä üÜö Comparaison du Jeu de Donn√©es WikiHint vs. TriviaHG

Le tableau ci-dessous compare **WikiHint** avec **TriviaHG**, le plus grand jeu de donn√©es pr√©c√©dent pour la g√©n√©ration d'indices. WikiHint offre **une meilleure convergence**, des **indices plus courts** et des **indices de meilleure qualit√©** selon plusieurs m√©triques d'√©valuation.

| **Jeu de Donn√©es** | **Sous-ensemble** | **Pertinence** | **Lisibilit√©** | **Convergence** | **Familiarit√©** | **Longueur** | **Fuite de R√©ponse (Moyenne)** | **Fuite de R√©ponse (Max.)** |
|--------------------|------------------|---------------|---------------|---------------|---------------|----------|------------------|------------------|
| TriviaHG          | Complet          | 0.95          | 0.71          | 0.57          | 0.77          | 20.82    | 0.23             | 0.44             |
| WikiHint          | Complet          | 0.98          | 0.72          | 0.73          | 0.75          | 17.82    | 0.24             | 0.49             |
| TriviaHG          | Entra√Ænement      | 0.95          | 0.73          | 0.57          | 0.75          | 21.19    | 0.22             | 0.44             |
| WikiHint          | Entra√Ænement      | 0.98          | 0.71          | 0.74          | 0.76          | 17.77    | 0.24             | 0.49             |
| TriviaHG          | Test              | 0.95          | 0.73          | 0.60          | 0.77          | 20.97    | 0.23             | 0.44             |
| WikiHint          | Test              | 0.98          | 0.83          | 0.72          | 0.73          | 18.32    | 0.24             | 0.47             |

üìå **Principaux R√©sultats** :
- **WikiHint surpasse TriviaHG** en **convergence**, ce qui signifie que ses indices aident les utilisateurs **√† trouver les r√©ponses plus efficacement**.
- **Les indices de WikiHint sont plus courts**, ce qui permet une **guidance plus concise et efficace**.

---

## üìäü§ñ √âvaluation des Indices G√©n√©r√©s

Ce tableau pr√©sente une **√©valuation des indices g√©n√©r√©s** par diff√©rents **LLMs (LLaMA-3.1, GPT-4)** en fonction de **la pertinence, la lisibilit√©, la convergence, la familiarit√©, la longueur des indices et la fuite de r√©ponse**. Il met en √©vidence l'impact du **finetuning (FT)** et de la **prise en compte de la r√©ponse (wA)** sur la qualit√© des indices.

| **Mod√®le** | **Config** | **Utilise la R√©ponse ?** | **Pert.** | **Lisib.** | **Conv. (LLaMA-8B)** | **Conv. (LLaMA-70B)** | **Fam.** | **Long.** | **Fuite (Moyenne)** | **Fuite (Max.)** |
|------------|-----------|----------------|-----------|-----------|------------------|------------------|-----------|---------|----------------|----------------|
| **GPT-4**  | Vanilla   | ‚úÖ              | 0.91      | 1.00      | 0.14             | 0.48             | 0.84      | 26.36   | 0.23           | 0.51           |
| **GPT-4**  | Vanilla   | ‚ùå              | 0.92      | 1.10      | 0.12             | 0.47             | 0.81      | 26.93   | 0.24           | 0.52           |
| **LLaMA-3.1-405b** | Vanilla | ‚úÖ     | 0.94      | 1.49      | 0.11             | 0.47             | 0.76      | 41.81   | 0.23           | 0.50           |
| **LLaMA-3.1-405b** | Vanilla | ‚ùå     | 0.92      | 1.53      | 0.10             | 0.45             | 0.78      | 50.91   | 0.23           | 0.50           |

üìå **Principaux Enseignements** :
- **Pertinence** : **Les mod√®les plus grands (405b, 70b) produisent de meilleurs indices** que les mod√®les plus petits (8b).
- **Lisibilit√©** : **GPT-4 g√©n√®re les indices les plus lisibles**.
- **Convergence** : **Les indices prenant en compte la r√©ponse (wA) aident les LLMs √† g√©n√©rer de meilleurs indices**.
- **Familiarit√©** : Les mod√®les plus grands g√©n√®rent **des indices plus familiers**, bas√©s sur des connaissances g√©n√©rales.
- **Longueur des indices** : **Les mod√®les ajust√©s finement (FTwA, FTwoA) g√©n√®rent des indices plus courts et plus efficaces**.

---

## üìÇ Structure du D√©p√¥t

```
üìÇ WikiHint/                                                # üóÇ Fichiers du jeu de donn√©es
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ Pipeline.png                                     # üìä Visualisation du pipeline du jeu de donn√©es
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ training.json                                    # üìä Ensemble d'entra√Ænement (900 questions, 4500 indices)
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ test.json                                        # üìä Ensemble de test (100 questions, 500 indices)
‚îÇ
‚îú‚îÄ‚îÄ üìÇ Experiments/                                         # üß™ Indices g√©n√©r√©s par les mod√®les
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ GPT-4-Vanilla-answer-agnostic.json
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ GPT-4-Vanilla-answer-aware.json
‚îÇ
‚îú‚îÄ‚îÄ üìÇ HintRank/                                            # üèÜ M√©thode de classement des indices
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ EvaluationMethod.png                             # üìä Visualisation de l‚Äô√©valuation de HintRank
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ hint_rank.py                                     # üìú Impl√©mentation de HintRank
‚îÇ
‚îú‚îÄ‚îÄ üìÇ HumanEvaluation/                                     # üë®‚Äçüî¨ Donn√©es d‚Äô√©valuation humaine
‚îÇ   ‚îú‚îÄ‚îÄ üìÇ Person_1/  
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üìë Part_1.xlsx
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üìë Part_2.xlsx
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ üìë Part_3.xlsx
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ üìÇ Person_2/ (M√™me structure que Person_1)
‚îÇ   ‚îú‚îÄ‚îÄ üìÇ Person_3/ (M√™me structure que Person_1)
‚îÇ
‚îî‚îÄ‚îÄ üìò README.md                                            # üìñ Ce fichier
```

---

## üìú Licence

Ce projet est sous licence **Creative Commons Attribution 4.0 International (CC BY 4.0)**. Vous √™tes libre d'utiliser, partager et adapter le jeu de donn√©es avec attribution.

## üìë Citation

Si ce travail vous est utile, merci de citer [üìúnotre article](https://doi.org/10.48550/arXiv.2412.01626) :

### üìÑ BibTeX :
```bibtex
@article{mozafari2025wikihinthumanannotateddatasethint,
      title={WikiHint: A Human-Annotated Dataset for Hint Ranking and Generation}, 
      author={Jamshid Mozafari and Florian Gerhold and Adam Jatowt},
      year={2025},
      eprint={2412.01626},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      doi={10.48550/arXiv.2412.01626}, 
}
```

---

## üôè Remerciements

Merci √† nos contributeurs et √† l'Universit√© d'Innsbruck pour leur soutien √† ce projet.
